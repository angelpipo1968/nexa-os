---
title: "Despliegue T√©cnico: Sovereign-RAG + Sovereign-KB"
author: "Angel ‚Äî Sovereign AI Stack"
date: "31 de diciembre de 2025"
subject: "Soberan√≠a digital, RAG offline-first, inteligencia aut√≥noma"
keywords: "Sovereign-RAG, offline AI, local LLM, ChromaDB, Llama 3.1, ciberseguridad"
lang: "es"
---

# Despliegue T√©cnico: Sovereign-RAG + Sovereign-KB  
*Integraci√≥n soberana, offline-first y aut√≥noma*  
**Autor**: Angel ‚Äî Las Vegas, NV  
**Fecha**: 31 de diciembre de 2025  

---

## 1. Resumen Ejecutivo
Sovereign-RAG + Sovereign-KB es un sistema de recuperaci√≥n aumentada de conocimiento (RAG) que opera de forma aut√≥noma sin conexi√≥n, pero se enriquece inteligentemente cuando hay acceso a internet.  
- **Objetivo**: Garantizar respuestas precisas, seguras y soberanas en cualquier entorno (a√©reo, aislado, censurado o de alto riesgo).  
- **Principios**: Cero fugas de datos, aprendizaje local, soberan√≠a cognitiva, multiling√ºismo (es/en/zh), y dise√±o minimalista-futurista.

## 2. Arquitectura del Sistema

#### Componentes clave:
| Componente              | Tecnolog√≠a                    | Funci√≥n |
|------------------------|------------------------------|--------|
| **Motor RAG online**   | LangChain + APIs verificadas | Consulta fuentes en tiempo real (OWASP, NIST, GitHub, etc.) |
| **Base de conocimiento local** | ChromaDB (modo persistente) | Almacena fragmentos vectorizados offline |
| **LLM local**          | Llama 3.1 8B (GGUF, Q5_K_M)  | Generaci√≥n de respuestas sin nube |
| **Router inteligente** | `smart_query()`              | Decide modo offline/online seg√∫n conectividad |
| **Aprendizaje por refuerzo humano** | `learner.py`         | Guarda correcciones como conocimiento validado |
| **Webhook de actualizaci√≥n** | FastAPI + Sovereign-RAG hooks | Recibe notificaciones de nuevas versiones |

> üîí **Ning√∫n dato sale del dispositivo sin consentimiento expl√≠cito.**

---

## 3. Estructura de Directorios (Integraci√≥n)

```
sovereign-rag/
‚îú‚îÄ‚îÄ sovereign_kb/                  ‚Üê M√≥dulo KB integrado
‚îÇ   ‚îú‚îÄ‚îÄ local_store.py             # Gestor ChromaDB
‚îÇ   ‚îú‚îÄ‚îÄ offline_query.py           # LLM local + retrieval
‚îÇ   ‚îú‚îÄ‚îÄ learner.py                 # Feedback loop (user-validated)
‚îÇ   ‚îî‚îÄ‚îÄ sync_agent.py              # Auto-actualizaci√≥n silenciosa
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ router.py                  # smart_query()
‚îÇ   ‚îî‚îÄ‚îÄ online_retriever.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ llama-3.1-8b.Q5_K_M.gguf   ‚Üê Modelo local (7.8 GB)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ vector_store/              ‚Üê KB persistente (~10 GB)
‚îÇ   ‚îî‚îÄ‚îÄ interactions/              ‚Üê Historial de validaciones
‚îî‚îÄ‚îÄ deploy_report_sovereign_kb.pdf ‚Üê ¬°Este documento!
```

---

## 4. Requisitos del Sistema

| Recurso               | M√≠nimo                     | Recomendado               |
|----------------------|----------------------------|---------------------------|
| SO                   | Linux / macOS / Windows 10+| Ubuntu 22.04 LTS          |
| CPU                  | 4 n√∫cleos                  | 8+ n√∫cleos (AVX2)         |
| RAM                  | 16 GB                      | 32 GB                     |
| Almacenamiento       | 25 GB SSD                  | 50 GB NVMe                |
| Red                  | Opcional (solo para sync)  | Con firewall estricto     |

> ‚úÖ Funciona en entornos aislados (air-gapped) tras instalaci√≥n inicial.

---

## 5. Modos de Operaci√≥n

| Modo          | Comportamiento                                                                 |
|---------------|--------------------------------------------------------------------------------|
| **Offline**   | Usa √∫nicamente ChromaDB + LLM local. Cero llamadas externas.                   |
| **Online**    | Consulta fuentes din√°micas ‚Üí valida respuesta ‚Üí almacena copia en KB local.     |
| **Aut√≥nomo**  | Si has validado respuestas antes, el sistema las prioriza (metadata: `user-validated`). |

---

## 6. Pol√≠tica de Soberan√≠a de Datos
- **Todos los embeddings y respuestas se procesan localmente**.
- **Ninguna interacci√≥n se env√≠a a terceros**.
- **Las fuentes online se descargan, no se consultan en vivo** (a menos que sea necesario y t√∫ lo permitas).
- **Actualizaciones mediante webhook cifrado** (opcional, desactivable).

---

## 7. Instrucciones de Instalaci√≥n (Resumen)

```bash
# 1. Clonar Sovereign-RAG (tu repositorio)
git clone https://github.com/angel/sovereign-rag.git
cd sovereign-rag

# 2. A√±adir Sovereign-KB
cp -r /ruta/a/sovereign-kb/sovereign_kb ./sovereign_kb/

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Descargar modelo LLM local
wget https://huggingface.co/TheBloke/Llama-3.1-8B-GGUF/resolve/main/llama-3.1-8b.Q5_K_M.gguf -P models/

# 5. Ingestar conocimiento inicial (ej. Wikipedia t√©cnica)
python sovereign_kb/local_store.py --ingest ./data/raw/

# 6. Iniciar API (offline-first por defecto)
uvicorn sovereign_rag.main:app --host 127.0.0.1 --port 8080
```
